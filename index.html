<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sai Narayan Sundaresan </title> <meta name="author" content="Sai Narayan Sundaresan"> <meta name="description" content="Research Associate at Adobe working on ML + Systems. I build efficient inference systems for LLMs and video generation by uncovering redundancies and enabling state reuse. "> <meta name="keywords" content="machine learning systems, LLM serving, caching, retrieval augmented generation, video generation, research, publications, portfolio"> <meta property="og:site_name" content="Sai Narayan Sundaresan"> <meta property="og:type" content="website"> <meta property="og:title" content="Sai Narayan Sundaresan | about"> <meta property="og:url" content="https://saisundaresan01.github.io/"> <meta property="og:description" content="Research Associate at Adobe working on ML + Systems. I build efficient inference systems for LLMs and video generation by uncovering redundancies and enabling state reuse. "> <meta property="og:image" content="assets/img/prof_pic.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="about"> <meta name="twitter:description" content="Research Associate at Adobe working on ML + Systems. I build efficient inference systems for LLMs and video generation by uncovering redundancies and enabling state reuse. "> <meta name="twitter:image" content="assets/img/prof_pic.jpg"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Sai Narayan Sundaresan"
        },
        "url": "https://saisundaresan01.github.io/",
        "@type": "WebSite",
        "description": "Research Associate at Adobe working on ML + Systems. I build efficient inference systems for LLMs and video generation by uncovering redundancies and enabling state reuse.
",
        "headline": "about",
        
        "sameAs": ["https://github.com/saisundaresan01","https://inspirehep.net/authors/1010907","https://www.linkedin.com/in/sai-narayan-sundaresan","https://scholar.google.com/citations?user=icwyFlQAAAAJ"],
        
        "name": "Sai Narayan Sundaresan",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A4&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://saisundaresan01.github.io/"> <script src="/assets/js/theme.js?aeacf2a47d23a8417ca7f50534483b6b"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%73%61%69%73%75%6E%64%61%72%65%73%61%6E%30%31@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/saisundaresan01" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/sai-narayan-sundaresan" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=icwyFlQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item"><a class="nav-link" href="/">About</a></li> <li class="nav-item"><a class="nav-link" href="#publications">Publications</a></li> <li class="nav-item"><a class="nav-link" href="#patents">Patents</a></li> <li class="nav-item"><a class="nav-link" href="/assets/pdf/cv.pdf" target="_blank" rel="noopener">CV</a></li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Sai Narayan</span> Sundaresan </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?ca9181e120a9fe41b742369ae6a0edfb" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <section id="about"></section> <p>I am a Research Associate at Adobe (Systems and Insights Group) working on Machine Learning and Systems. My work focuses on making generative models efficient at inference time by uncovering redundancies and enabling reuse of computation.</p> <p>At Adobe, I have worked on efficient LLM serving (chunk-cache reuse for RAG) and on caching for video generation models. Before that, I completed a Dual Degree (B.Tech, M.Tech) from the department of Industrial and Systems Engineering at IIT Kharagpur (GPA 9.15/10.00) with a micro‑specialization in AI. With over 1 year of experience in academic and industrial research, I have publications in SIGMOD, EMNLP, and INTERSPEECH.</p> <p>If you would like to discuss ideas or collaborate, feel free to contact me at <a href="mailto:saisundaresan01@gmail.com">saisundaresan01@gmail.com</a>.</p> <section id="publications"></section> <h1>Publications</h1> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP</abbr> </div> <div id="sundaresan2025emnlp_browsing" class="col-sm-8"> <div class="title">Subjective Behaviors and Preferences in LLM: Language of Browsing</div> <div class="author"> <strong>Sai Sundaresan</strong>, Harshita Chopra, Atanu Sinha, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Koustava Goswami, Nagasai Naidu, Raghav Karan, N. Anushka' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In The 30th Conference on Empirical Methods in Natural Language Processing</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2508.15474" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>A Large Language Model (LLM) offers versatility across domains and tasks, purportedly benefiting users with a wide variety of behaviors and preferences. We question this perception about an LLM when users have inherently subjective behaviors and preferences, as seen in their ubiquitous and idiosyncratic browsing of websites or apps. The sequential behavior logs of pages, thus generated, form something akin to each user’s self-constructed "language", albeit without the structure and grammar imbued in natural languages. We ask: (i) Can a small LM represent the "language of browsing" better than a large LM? (ii) Can an LM with a single set of parameters (or, single LM) adequately capture myriad users’ heterogeneous, subjective behaviors and preferences? (iii) Can a single LM with high average performance, yield low variance in performance to make alignment good at user level? We introduce clusterwise LM training, HeTLM (Heterogeneity aware Training of Language Model), appropriate for subjective behaviors. We find that (i) a small LM trained using a page-level tokenizer outperforms large pretrained or finetuned LMs; (ii) HeTLM with heterogeneous cluster specific set of parameters outperforms a single LM of the same family, controlling for the number of parameters; and (iii) a higher mean and a lower variance in generation ensues, implying improved alignment.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sundaresan2025emnlp_browsing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Subjective Behaviors and Preferences in LLM: Language of Browsing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sundaresan, Sai and Chopra, Harshita and Sinha, Atanu R. and Goswami, Koustava and Naidu, Nagasai Saketh and Karan, Raghav and Anushka, N.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 30th Conference on Empirical Methods in Natural Language Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SIGMOD</abbr> </div> <div id="agarwal2025sigmod_cachecraft" class="col-sm-8"> <div class="title">Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation</div> <div class="author"> Shubham Agarwal<sup>*</sup>, <strong>Sai Sundaresan<sup>*</sup></strong>, Subrata Mitra, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Debabrata Mahapatra, Archit Gupta, Rounak Sharma, Nirmal Kapu, Tong Yu, Shiv Saini' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In The 44th ACM SIGMOD International Conference on Management of Data</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.15734" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>Retrieval-Augmented Generation (RAG) is often used with Large Language Models (LLMs) to infuse domain knowledge or user-specific information. In RAG, given a user query, a retriever extracts chunks of relevant text from a knowledge base. These chunks are sent to an LLM as part of the input prompt. Typically, any given chunk is repeatedly retrieved across user questions. However, currently, for every question, attention-layers in LLMs fully compute the key values (KVs) repeatedly for the input chunks, as state-of-the-art methods cannot reuse KV-caches when chunks appear at arbitrary locations with arbitrary contexts. Naive reuse leads to output quality degradation. This leads to potentially redundant computations on expensive GPUs and increases latency. In this work, we propose Cache-Craft, a system for managing and reusing precomputed KVs corresponding to the text chunks (we call chunk-caches) in RAG-based systems. We present how to identify chunk-caches that are reusable, how to efficiently perform a small fraction of recomputation to fix the cache to maintain output quality, and how to efficiently store and evict chunk-caches in the hardware for maximizing reuse while masking any overheads. With real production workloads as well as synthetic datasets, we show that Cache-Craft reduces redundant computation by 51% over SOTA prefix-caching and 75% over full recomputation. Additionally, with continuous batching on a real production workload, we get a 1.6X speed up in throughput and a 2X reduction in end-to-end response latency over prefix-caching while maintaining quality, for both the LLaMA-3-8B and LLaMA-3-70B models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">agarwal2025sigmod_cachecraft</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Agarwal, Shubham and Sundaresan, Sai and Mitra, Subrata and Mahapatra, Debabrata and Gupta, Archit and Sharma, Rounak and Kapu, Nirmal Joshua and Yu, Tong and Saini, Shiv}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 44th ACM SIGMOD International Conference on Management of Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ORSI</abbr> </div> <div id="sundaresan2024orsi_clearance_sale" class="col-sm-8"> <div class="title">Clearance Sale Models under Competition</div> <div class="author"> <strong>Sai Sundaresan</strong> and Anand Abraham </div> <div class="periodical"> <em>In The International Conference on Trends in Business Analytics &amp; Management</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.som.iitb.ac.in/bams-orsi-2024/publications_and_awards/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Retailers frequently face challenges in demand forecasting which can lead to excess inventory. This is often addressed through clearance sales where the inventory is sold at a markdown price. In these situations, the presence of competition can largely alter the optimal strategy for a retailer. This study proposes a two-period model that determines the optimal initial order quantity for a retailer in the presence of competition. Our model highlights how competition dynamics affect revenue, demonstrating significant gain over the traditional Newsvendor model in limited clearance scenarios. Furthermore, we extend the model to study the impact of risk aversion on these decisions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sundaresan2024orsi_clearance_sale</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Clearance Sale Models under Competition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sundaresan, Sai and Abraham, Anand}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The International Conference on Trends in Business Analytics &amp; Management}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">abs_only</span> <span class="p">=</span> <span class="s">{Retailers frequently face challenges in demand forecasting which can lead to excess inventory. This is often addressed through clearance sales where the inventory is sold at a markdown price. In these situations, the presence of competition can largely alter the optimal strategy for a retailer. This study proposes a two-period model that determines the optimal initial order quantity for a retailer in the presence of competition. Our model highlights how competition dynamics affect revenue, demonstrating significant gain over the traditional Newsvendor model in limited clearance scenarios. Furthermore, we extend the model to study the impact of risk aversion on these decisions.}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLST</abbr> </div> <div id="sundaresan2024iclst_hidden_city" class="col-sm-8"> <div class="title">Single Resource Capacity Control Model for Hidden City Ticketing</div> <div class="author"> <strong>Sai Sundaresan</strong> and Anand Abraham </div> <div class="periodical"> <em>In The International Conference on Logistics, Supply Chain and Transportation</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/book/9789819506026" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Skip-Lagging is a practice where a strategic customer takes advantage of a situation where a connecting flight through an intermediate city is cheaper than a direct flight to the city. In such a case, the customer wishing to travel to an intermediate city will purchase a connecting flight through the city and deplane at the connection point. In this paper, we try to model the effect of skip-lagging behaviour on airline revenue under a single resource capacity control scenario. Our Dual Booking limit considers separate booking limits for the direct and connecting flight segments while determining the optimal seat allocation. We demonstrate that our model achieves a significant revenue increase compared to the traditional single booking limit model. Moreover, we show our model incentivizes customers to refrain from engaging in skip-lagging practices. We also analyze the solution space of the model to develop an efficient Integer Linear Programming formulation for the seat allocation problem. Furthermore, we extend the model to scenarios where multiple Skip-Lagging opportunities are present for strategic customers.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sundaresan2024iclst_hidden_city</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Single Resource Capacity Control Model for Hidden City Ticketing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sundaresan, Sai and Abraham, Anand}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The International Conference on Logistics, Supply Chain and Transportation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">abs_only</span> <span class="p">=</span> <span class="s">{Skip-Lagging is a practice where a strategic customer takes advantage of a situation where a connecting flight through an intermediate city is cheaper than a direct flight to the city. In such a case, the customer wishing to travel to an intermediate city will purchase a connecting flight through the city and deplane at the connection point. In this paper, we try to model the effect of skip-lagging behaviour on airline revenue under a single resource capacity control scenario. Our Dual Booking limit considers separate booking limits for the direct and connecting flight segments while determining the optimal seat allocation. We demonstrate that our model achieves a significant revenue increase compared to the traditional single booking limit model. Moreover, we show our model incentivizes customers to refrain from engaging in skip-lagging practices. We also analyze the solution space of the model to develop an efficient Integer Linear Programming formulation for the seat allocation problem. Furthermore, we extend the model to scenarios where multiple Skip-Lagging opportunities are present for strategic customers.}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">INTERSPEECH</abbr> </div> <div id="bhogale2023interspeech_vistaar" class="col-sm-8"> <div class="title">Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR</div> <div class="author"> Kaushal Bhogale<sup>*</sup>, <strong>Sai Sundaresan<sup>*</sup></strong>, Abhigyan Raman, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Tahir Javed, Mitesh Khapra, Pratyush Kumar' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In The 24th INTERSPEECH Conference</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.15386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>Improving ASR systems is necessary to make new LLM-based use-cases accessible to people across the globe. In this paper, we focus on Indian languages, and make the case that diverse benchmarks are required to evaluate and improve ASR systems for Indian languages. To address this, we collate Vistaar as a set of 59 benchmarks across various language and domain combinations, on which we evaluate 3 publicly available ASR systems and 2 commercial systems. We also train IndicWhisper models by fine-tuning the Whisper models on publicly available training datasets across 12 Indian languages totalling to 10.7K hours. We show that IndicWhisper significantly improves on considered ASR systems on the Vistaar benchmark. Indeed, IndicWhisper has the lowest WER in 39 out of the 59 benchmarks, with an average reduction of 4.1 WER. We open-source all datasets, code and models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bhogale2023interspeech_vistaar</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bhogale, Kaushal Santosh and Sundaresan, Sai and Raman, Abhigyan and Javed, Tahir and Khapra, Mitesh M. and Kumar, Pratyush}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 24th INTERSPEECH Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">INTERSPEECH</abbr> </div> <div id="javed2023interspeech_svarah" class="col-sm-8"> <div class="title">Svarah: Evaluating English ASR Systems on Indian Accents</div> <div class="author"> Tahir Javed, Sakshi Joshi, Vignesh Nagarajan, <strong>Sai Sundaresan</strong>, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Janki Nawale, Abhigyan Raman, Kaushal Bhogale, Pratyush Kumar, Mitesh Khapra' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In The 24th INTERSPEECH Conference</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.15760" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>India is the second largest English-speaking country in the world with a speaker base of roughly 130 million. Thus, it is imperative that automatic speech recognition (ASR) systems for English should be evaluated on Indian accents. Unfortunately, Indian speakers find a very poor representation in existing English ASR benchmarks such as LibriSpeech, Switchboard, Speech Accent Archive, etc. In this work, we address this gap by creating Svarah, a benchmark that contains 9.6 hours of transcribed English audio from 117 speakers across 65 geographic locations throughout India, resulting in a diverse range of accents. Svarah comprises both read speech and spontaneous conversational data, covering various domains, such as history, culture, tourism, etc., ensuring a diverse vocabulary. We evaluate 6 open source ASR models and 2 commercial ASR systems on Svarah and show that there is clear scope for improvement on Indian accents. Svarah as well as all our code will be publicly available.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">javed2023interspeech_svarah</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Svarah: Evaluating English ASR Systems on Indian Accents}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Javed, Tahir and Joshi, Sakshi and Nagarajan, Vignesh and Sundaresan, Sai and Nawale, Janki and Raman, Abhigyan and Bhogale, Kaushal and Kumar, Pratyush and Khapra, Mitesh M.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 24th INTERSPEECH Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <section id="patents"></section> <h1>Patents</h1> <div class="patents"> <div class="d-flex align-items-start mb-3"> <span class="badge badge-info mr-3">USPTO</span> <div> <div><strong>Heterogenous LLMs for Subjective Behaviors.</strong></div> <div><em>US Patent App. 19/215,758 Filed</em></div> <div>Sai Narayan Sundaresan, Atanu R Sinha, Harshita Chopra, Koustava Goswami, Raghav Karan, Nagasai Saketh Naidu, Anushka N.</div> </div> </div> <div class="d-flex align-items-start mb-3"> <span class="badge badge-info mr-3">USPTO</span> <div> <div><strong>Utilizing Digital Page Sequence Tokens with Large Language Models to Generate Digital User Activity Predictions.</strong></div> <div><em>US Patent App. 19/050,836 Filed</em></div> <div>Harshita Chopra, Nagasai Saketh Naidu, Raghav Karan, Anushka N, Atanu R Sinha, Koustava Goswami, Sai Narayan Sundaresan.</div> </div> </div> <div class="d-flex align-items-start mb-3"> <span class="badge badge-info mr-3">USPTO</span> <div> <div><strong>Managing Chunk Caches for Efficient Retrieval-Augmented Generation.</strong></div> <div><em>US Patent App. 19/074,061 Filed</em></div> <div>Shubham Agarwal, Sai Narayan Sundaresan, Subrata Mitra, Debabrata Mahapatra, Archit Gupta, Rounak Sharma, Nirmal Joshua Kapu, Tong Yu, Shiv Saini.</div> </div> </div> </div> <section id="cv"></section> <section id="contact"></section> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%73%61%69%73%75%6E%64%61%72%65%73%61%6E%30%31@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/saisundaresan01" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/sai-narayan-sundaresan" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=icwyFlQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note">The best way to contact me is through gmail. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Sai Narayan Sundaresan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>